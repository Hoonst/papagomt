{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21daec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from typing import List, Set, Dict, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5afd91df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_source_loc = 'naver/train_source.txt'\n",
    "train_target_loc = 'naver/train_target.txt'\n",
    "\n",
    "test_source_loc = 'naver/test_source.txt'\n",
    "test_target_loc = 'naver/test_target.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fcc1d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_process(file_loc):\n",
    "    file = open(file_loc, 'r')\n",
    "    file_lines = file.readlines()\n",
    "    file_lines = [list(map(int, line.split())) for line in file_lines]\n",
    "    return file_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac15d283",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_source = open_process(train_source_loc)\n",
    "train_target = open_process(train_target_loc)\n",
    "\n",
    "test_source = open_process(test_source_loc)\n",
    "test_target = open_process(test_target_loc)\n",
    "\n",
    "train_src_vocab = set([i for line in train_source for i in line])\n",
    "train_tgt_vocab = set([i for line in train_target for i in line])\n",
    "\n",
    "test_src_vocab = set([i for line in test_source for i in line])\n",
    "test_tgt_vocab = set([i for line in test_target for i in line])\n",
    "\n",
    "train_src_vocab_dict = {value: idx for idx, value in enumerate(sorted(train_src_vocab))}\n",
    "train_tgt_vocab_dict = {value: idx for idx, value in enumerate(sorted(train_tgt_vocab))}\n",
    "\n",
    "test_src_vocab_dict = {value: idx for idx, value in enumerate(sorted(test_src_vocab))}\n",
    "test_tgt_vocab_dict = {value: idx for idx, value in enumerate(sorted(test_tgt_vocab))}\n",
    "\n",
    "train_src_vocab_size = len(train_src_vocab)\n",
    "train_tgt_vocab_size = len(train_tgt_vocab)\n",
    "\n",
    "test_src_vocab_size = len(test_src_vocab)\n",
    "test_tgt_vocab_size = len(test_tgt_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "288c42a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_source = [[train_src_vocab_dict[i] for i in seq] for seq in train_source]\n",
    "train_target = [[train_tgt_vocab_dict[i] for i in seq] for seq in train_target]\n",
    "\n",
    "test_source = [[test_src_vocab_dict[i] for i in seq] for seq in test_source]\n",
    "test_target = [[test_tgt_vocab_dict[i] for i in seq] for seq in test_target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29371c39",
   "metadata": {},
   "source": [
    "68의 존재는 무엇인가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7329eaf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f483687b640>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAFgCAYAAACFYaNMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAT9ElEQVR4nO3df6zddX3H8efbIvjb8uOuYS0JOJgbcZuaK6CYBWFKQWfZRObij8LqSjaqOJxaNBnZ9g8mTsBBGA04SkIARQzVGRhW1GzRakWUQkGqE+kN0Fuh6DSC1ff+OJ+6Q3vLvZfec97n3PN8JCfn+/18v+fk/Qmnr/vlc76fz4nMRJLUf8+qLkCSRpUBLElFDGBJKmIAS1IRA1iSiuxXXUAvLF26NG+55ZbqMiRpl5iqcV5eAW/fvr26BEma1rwMYEkaBgawJBUxgCWpiAEsSUUMYEkq0rMAjohPRsS2iNjU1XZQRNwWEfe35wNbe0TEJyJiS0R8NyJe2fWa5e38+yNiea/qlaR+6+UV8NXA0t3aVgPrM/MoYH3bBzgFOKo9VgKXQyewgQuAY4FjgAt2hbYkDbueBXBmfhV4dLfmZcDatr0WOK2r/Zrs+DqwMCIOBU4GbsvMRzPzMeA29gx1SRpK/R4DXpSZD7Xth4FFbXsx8GDXeVtb297a9xARKyNiY0RsnJycnNuqJakHyr6Ey85K8HO2GnxmrsnM8cwcHxsbm6u3laSe6XcAP9KGFmjP21r7BHBY13lLWtve2iVp6PU7gNcBu+5kWA7c3NX+rnY3xHHA422o4lbgDRFxYPvy7Q2tTZKGXs9WQ4uI64ATgEMiYiuduxkuBD4VESuAB4Az2ulfAE4FtgA/B84CyMxHI+KfgW+28/4pM3f/Yk+ShlLMxx/lHB8fz40bN1aXIUm7TLkc5bxcD/iZOvPsVUxs3/GUtsWHLOTqKy6tKUjSvGYAd5nYvoODTz7nqW23XlZUjaT5zrUgJKmIASxJRQxgSSpiAEtSEQNYkooYwJJUxACWpCIGsCQVMYAlqYgBLElFDGBJKmIAS1IRA1iSihjAklTEAJakIgawJBUxgCWpiAEsSUUMYEkqYgBLUhEDWJKKGMCSVMQAlqQiBrAkFTGAJamIASxJRQxgSSpiAEtSEQNYkooYwJJUxACWpCIGsCQVMYAlqYgBLElFDGBJKmIAS1IRA1iSihjAklTEAJakIgawJBUxgCWpiAEsSUUMYEkqYgBLUhEDWJKKGMCSVMQAlqQiBrAkFTGAJamIASxJRQxgSSpSEsAR8XcRcXdEbIqI6yLiORFxRERsiIgtEXFDROzfzj2g7W9pxw+vqFmS5lrfAzgiFgPvBcYz82XAAuBtwEeBizLzSOAxYEV7yQrgsdZ+UTtPkoZe1RDEfsBzI2I/4HnAQ8CJwI3t+FrgtLa9rO3Tjp8UEdG/UiWpN/oewJk5AXwM+BGd4H0c+BawIzN3ttO2Aovb9mLgwfbane38g3d/34hYGREbI2Lj5ORkbzshSXOgYgjiQDpXtUcAvw08H1i6r++bmWsyczwzx8fGxvb17SSp5yqGIP4E+J/MnMzMXwI3AccDC9uQBMASYKJtTwCHAbTjLwZ+3N+SJWnuVQTwj4DjIuJ5bSz3JOAe4Hbg9HbOcuDmtr2u7dOOfykzs4/1SlJPVIwBb6DzZdodwF2thjXAh4DzImILnTHeq9pLrgIObu3nAav7XbMk9cJ+058y9zLzAuCC3Zp/ABwzxbm/AN7aj7okqZ+cCSdJRQxgSSpiAEtSEQNYkooYwJJUxACWpCIGsCQVMYAlqYgBLElFDGBJKmIAS1IRA1iSihjAklTEAJakIgawJBUxgCWpiAEsSUUMYEkqYgBLUhEDWJKKGMCSVMQAlqQiBrAkFTGAJamIASxJRQxgSSpiAEtSEQNYkooYwJJUxACWpCIGsCQVMYAlqYgBLElFDGBJKmIAS1IRA1iSihjAklTEAJakIgawJBUxgCWpiAEsSUUMYEkqYgBLUhEDWJKKGMCSVMQAlqQiBrAkFTGAJamIASxJRQxgSSpiAEtSkf2qCxh0m+/exOvf8o492hcfspCrr7i0oCJJ84UBPI0ncwEHn3zOHu0Tt15WUI2k+aQkgCNiIXAl8DIggb8C7gNuAA4HfgickZmPRUQAlwCnAj8HzszMO/pfda0zz17FxPYde7R7JS4Nr6or4EuAWzLz9IjYH3ge8GFgfWZeGBGrgdXAh4BTgKPa41jg8vY8Uia27/BKXJpn+v4lXES8GPhj4CqAzHwyM3cAy4C17bS1wGltexlwTXZ8HVgYEYf2tWhJ6oGKuyCOACaBf4+Ib0fElRHxfGBRZj7UznkYWNS2FwMPdr1+a2uTpKFWEcD7Aa8ELs/MVwA/ozPc8BuZmXTGhmcsIlZGxMaI2Dg5OTlnxUpSr1QE8FZga2ZuaPs30gnkR3YNLbTnbe34BHBY1+uXtLanyMw1mTmemeNjY2M9K16S5krfAzgzHwYejIiXtqaTgHuAdcDy1rYcuLltrwPeFR3HAY93DVVI0tCqugviPcC17Q6IHwBn0flj8KmIWAE8AJzRzv0CnVvQttC5De2s/pcrSXOvJIAz805gfIpDJ01xbgJ73n8lSUPOtSAkqYgBLElFDGBJKmIAS1IRA1iSihjAklTEAJakIgawJBUxgCWpyIxmwkXE8Zn539O1jRJ/K07SvprpVOR/pbNi2XRtI8PfipO0r542gCPi1cBrgLGIOK/r0IuABb0sTJLmu+mugPcHXtDOe2FX+0+A03tVlCSNgqcN4Mz8CvCViLg6Mx/oU02SNBJmOgZ8QESsofOT8b95TWae2IuiJGkUzDSAPw38G3Al8KvelSNJo2OmAbwzMy/vaSWSNGJmOhHjcxHxtxFxaEQctOvR08okaZ6b6RXwrh/L/EBXWwIvmdtyJGl0zCiAM/OIXhciSaNmplOR3zVVe2ZeM7flSNLomOkQxKu6tp9D59eL7wAMYEl6hmY6BPGe7v2IWAhc34uCJGlUPNPlKH8GOC4sSftgpmPAn6Nz1wN0FuH5feBTvSpKkkbBTMeAP9a1vRN4IDO39qAeSRoZMxqCaIvy3EtnRbQDgSd7WZQkjYIZBXBEnAF8A3grcAawISJcjlKS9sFMhyA+ArwqM7cBRMQY8EXgxl4VJknz3UzvgnjWrvBtfjyL10qSpjDTK+BbIuJW4Lq2/xfAF3pTkiSNhul+E+5IYFFmfiAi/hx4bTv0NeDaXhcnSfPZdFfAFwPnA2TmTcBNABHxB+3Yn/awNkma16Ybx12UmXft3tjaDu9JRZI0IqYL4IVPc+y5c1iHJI2c6QJ4Y0T89e6NEfFu4Fu9KUmSRsN0Y8DvAz4bEW/n/wN3HNgf+LMe1iVJ897TBnBmPgK8JiJeB7ysNf9HZn6p55VJ0jw30/WAbwdu73EtkjRSnM0mSUUMYEkqYgBLUhEDWJKKGMCSVMQAlqQiM12OUjO0+e5NvP4t73hK2+JDFnL1FZcWVSRpUBnAc+zJXMDBJ5/zlLaJWy8rqkbSIHMIQpKKGMCSVMQAlqQiBrAkFTGAJamIASxJRQxgSSpSFsARsSAivh0Rn2/7R0TEhojYEhE3RMT+rf2Atr+lHT+8qmZJmkuVV8DnApu79j8KXJSZRwKPASta+wrgsdZ+UTtPkoZeSQBHxBLgjcCVbT+AE4Eb2ylrgdPa9rK2Tzt+UjtfkoZa1RXwxcAHgV+3/YOBHZm5s+1vBRa37cXAgwDt+OPt/KeIiJURsTEiNk5OTvawdEmaG30P4Ih4E7AtM+f0Z+0zc01mjmfm+NjY2Fy+tST1RMViPMcDb46IU4HnAC8CLgEWRsR+7Sp3CTDRzp8ADgO2RsR+wIuBH/e/bM3WmWevYmL7jj3aXR1O6uh7AGfm+cD5ABFxAvD3mfn2iPg0cDpwPbAcuLm9ZF3b/1o7/qXMzD6XrWdgYvuOPVaGA1eHk3YZpPuAPwScFxFb6IzxXtXarwIObu3nAauL6pOkOVW6HnBmfhn4ctv+AXDMFOf8AnhrXwuTpD4YpCtgSRopBrAkFTGAJamIASxJRQxgSSpiAEtSEX+Wvg82372J17/lHXu0OyNMGm0GcB88mQucESZpDw5BSFIRA1iSihjAklTEAJakIgawJBUxgCWpiAEsSUUMYEkqYgBLUhFnwhVyirI02gzgQk5RlkabQxCSVMQr4AE01dDEvffdz/Enz+z1Z569iontO/Zod2hDGiwG8ACaamjiiU2rZvz6ie07HNqQhoBDEJJUxCvgIbevwxWS6hjAQ25fhysk1XEIQpKKGMCSVMQhiBHizDtpsBjAI8SZd9JgcQhCkooYwJJUxACWpCIGsCQVMYAlqYgBLElFDGBJKuJ9wJpygoaTM6TeM4A15QQNJ2dIvWcAa0pOW5Z6zwDWlJy2LPWeX8JJUhEDWJKKGMCSVMQAlqQiBrAkFfEuCM2Kt6dJc8cA1qx4e5o0dxyCkKQiBrAkFTGAJamIASxJRQxgSSpiAEtSkb4HcEQcFhG3R8Q9EXF3RJzb2g+KiNsi4v72fGBrj4j4RERsiYjvRsQr+12zJPVCxRXwTuD9mXk0cBxwTkQcDawG1mfmUcD6tg9wCnBUe6wELu9/yZI09/oewJn5UGbe0bZ/CmwGFgPLgLXttLXAaW17GXBNdnwdWBgRh/a3akmae6VjwBFxOPAKYAOwKDMfaoceBha17cXAg10v29radn+vlRGxMSI2Tk5O9q5oSZojZQEcES8APgO8LzN/0n0sMxPI2bxfZq7JzPHMHB8bG5vDSiWpN0oCOCKeTSd8r83Mm1rzI7uGFtrzttY+ARzW9fIlrU2ShlrfF+OJiACuAjZn5se7Dq0DlgMXtuebu9pXRcT1wLHA411DFRoQU62Sdu9993P8yUUFSUOgYjW044F3AndFxJ2t7cN0gvdTEbECeAA4ox37AnAqsAX4OXBWX6vVjEy1StoTm1YVVSMNh74HcGb+FxB7OXzSFOcnsOf6h5I05JwJJ0lFDGBJKmIAS1IRA1iSihjAklTEAJakIgawJBUxgCWpiAEsSUUMYEkqYgBLUhEDWJKKVKyGphE31dKVAIsPWcjVV1xaUJFUwwBW3021dCXAxK2XFVQj1XEIQpKKGMCSVMQAlqQiBrAkFTGAJamIASxJRQxgSSrifcAaaGeevYqJ7Tv2aHfShuYDA1gDbWL7DidtaN5yCEKSihjAklTEAJakIgawJBXxSzgNJZe01HxgAGsouaSl5gOHICSpiAEsSUUMYEkq4hiwBsZUX6zde9/9HH9yUUFSjxnAGhhTfbH2xKZVRdVIvecQhCQVMYAlqYgBLElFHAPWvDLVF3nOjtOgMoA1r0z1Rd5sZ8dNtQi8Ia5eMICl3Uy1CLxTnNULjgFLUhEDWJKKOASheW9vS1f+8Pvf4/Df+d092p19p34xgDXv7W3pyu/8y6op2519p35xCEKSihjAklTEAJakIgawJBUxgCWpiHdBSDPgrzCrFwxgaQb8FWb1ggEs7YPZTPLY28QPr6JHlwEs7YPZTPLY28QPr6JHlwEsFfMqenQNTQBHxFLgEmABcGVmXlhckjQnvIoeXUMRwBGxALgMeD2wFfhmRKzLzHtqK5MGw1zcpeFC9P03FAEMHANsycwfAETE9cAywACW2PtV9Bc//jd7BPPTrgL33ouf0ra3K+upwnpv7z3bYZNB+UPQjzoiM+fszXolIk4Hlmbmu9v+O4FjM3NV1zkrgZVt96XAfdO87SHA9h6U22/2Y7DYj8EyKP3YnplLd28clivgaWXmGmDNTM+PiI2ZOd7DkvrCfgwW+zFYBr0fwzIVeQI4rGt/SWuTpKE1LAH8TeCoiDgiIvYH3gasK65JkvbJUAxBZObOiFgF3ErnNrRPZubd+/i2Mx6uGHD2Y7DYj8Ey0P0Yii/hJGk+GpYhCEmadwxgSSoycgEcEUsj4r6I2BIRq6vrmY2I+GREbIuITV1tB0XEbRFxf3s+sLLG6UTEYRFxe0TcExF3R8S5rX3Y+vGciPhGRHyn9eMfW/sREbGhfb5uaF8aD7yIWBAR346Iz7f9Ye3HDyPiroi4MyI2traB/WyNVAB3TWk+BTga+MuIOLq2qlm5Gtj9Zu7VwPrMPApY3/YH2U7g/Zl5NHAccE77bzBs/XgCODEz/wh4ObA0Io4DPgpclJlHAo8BK+pKnJVzgc1d+8PaD4DXZebLu+7/HdjP1kgFMF1TmjPzSWDXlOahkJlfBR7drXkZsLZtrwVO62dNs5WZD2XmHW37p3T+0S9m+PqRmfm/bffZ7ZHAicCNrX3g+wEQEUuANwJXtv1gCPvxNAb2szVqAbwYeLBrf2trG2aLMvOhtv0wsKiymNmIiMOBVwAbGMJ+tP9tvxPYBtwGfB/YkZk72ynD8vm6GPgg8Ou2fzDD2Q/o/BH8z4j4VlueAAb4szUU9wFrZjIzI2Io7iuMiBcAnwHel5k/6Vx0dQxLPzLzV8DLI2Ih8Fng92ormr2IeBOwLTO/FREnFJczF16bmRMR8VvAbRFxb/fBQftsjdoV8Hyc0vxIRBwK0J63FdczrYh4Np3wvTYzb2rNQ9ePXTJzB3A78GpgYUTsurAZhs/X8cCbI+KHdIbkTqSz7vaw9QOAzJxoz9vo/FE8hgH+bI1aAM/HKc3rgOVtezlwc2Et02rji1cBmzPz412Hhq0fY+3Kl4h4Lp21qjfTCeLT22kD34/MPD8zl2Tm4XT+PXwpM9/OkPUDICKeHxEv3LUNvAHYxCB/tjJzpB7AqcD36IzXfaS6nlnWfh3wEPBLOuNyK+iM160H7ge+CBxUXec0fXgtnXG67wJ3tsepQ9iPPwS+3fqxCfiH1v4S4BvAFuDTwAHVtc6iTycAnx/WfrSav9Med+/69z3Iny2nIktSkVEbgpCkgWEAS1IRA1iSihjAklTEAJakIgawJBUxgCWpyP8B0EssBFF3p68AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_target_len = list(map(len, train_target))\n",
    "sns.displot(train_target_len)\n",
    "\n",
    "test_source_len = list(map(len, test_source))\n",
    "sns.displot(test_source_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4aa24623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train source length: 7260\n",
      "mean length: 18\n",
      "max / min length: (81, 2)\n",
      "vocab size: 53\n",
      "==============================\n",
      "train target length: 7260\n",
      "mean length: 10\n",
      "max / min length: (54, 1)\n",
      "vocab size: 595\n",
      "test source length: 2000\n",
      "mean length: 19\n",
      "max / min length: (84, 1)\n",
      "vocab size: 45\n",
      "test target length: 2000\n",
      "mean length: 10\n",
      "max / min length: (54, 1)\n",
      "vocab size: 495\n"
     ]
    }
   ],
   "source": [
    "print(f'train source length: {len(train_source)}')\n",
    "print(f'mean length: {int(np.mean([len(i) for i in train_source]))}')\n",
    "print(f'max / min length: {len(max(train_source, key=len)), len(min(train_source, key=len))}')\n",
    "print(f'vocab size: {len(train_src_vocab)}')\n",
    "print('='*30)\n",
    "\n",
    "print(f'train target length: {len(train_target)}')\n",
    "print(f'mean length: {int(np.mean([len(i) for i in train_target]))}')\n",
    "print(f'max / min length: {len(max(train_target, key=len)), len(min(train_target, key=len))}')\n",
    "print(f'vocab size: {len(train_tgt_vocab)}')\n",
    "\n",
    "print(f'test source length: {len(test_source)}')\n",
    "print(f'mean length: {int(np.mean([len(i) for i in test_source]))}')\n",
    "print(f'max / min length: {len(max(test_source, key=len)), len(min(test_source, key=len))}')\n",
    "print(f'vocab size: {len(test_src_vocab)}')\n",
    "\n",
    "print(f'test target length: {len(test_target)}')\n",
    "print(f'mean length: {int(np.mean([len(i) for i in test_target]))}')\n",
    "print(f'max / min length: {len(max(test_target, key=len)), len(min(test_target, key=len))}')\n",
    "print(f'vocab size: {len(test_tgt_vocab)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a489e6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, src_seq: List, tgt_seq: List):\n",
    "        self.src_seq = src_seq\n",
    "        self.tgt_seq = tgt_seq\n",
    "        \n",
    "        self.src_maxlen = len(max(self.src_seq, key=len))\n",
    "        self.tgt_maxlen = len(max(self.tgt_seq, key=len))\n",
    "        \n",
    "    def __len__(self)-> int:\n",
    "        return len(self.src_seq)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> List:\n",
    "        src = torch.tensor(self.src_seq[idx])\n",
    "        tgt = torch.tensor(self.tgt_seq[idx])\n",
    "        \n",
    "        return src, tgt\n",
    "    \n",
    "def pad_collate(batch) -> (List, List):\n",
    "    (xs, ys)= zip(*batch)\n",
    "    \n",
    "    x_lens = [len(x) for x in xs]\n",
    "    y_lens = [len(y) for y in ys]\n",
    "\n",
    "    x_pad = pad_sequence(xs, batch_first=True, padding_value=-1)\n",
    "    y_pad = pad_sequence(ys, batch_first=True, padding_value=-1)\n",
    "    \n",
    "    return x_pad, y_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee0138a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "seq_dataset = SeqDataset(train_source, train_target)\n",
    "seq_dataloader = DataLoader(seq_dataset, batch_size=batch_size, shuffle=True, collate_fn = pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "370d1ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        # Defining some parameters\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        #Defining the layers\n",
    "        # RNN Layer\n",
    "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)   \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # Initializing hidden state for first input using method defined below\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        \n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = out.contiguous().view(-1, self.hidden_dim)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
    "        # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d278f267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cdf4581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (rnn): RNN(53, 300, num_layers=20, batch_first=True)\n",
       "  (fc): Linear(in_features=300, out_features=595, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the model with hyperparameters\n",
    "model = Model(input_size=train_src_vocab_size, output_size=train_tgt_vocab_size, hidden_dim=300, n_layers=20)\n",
    "# We'll also set the model to the device that we defined earlier (default is CPU)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2a5bd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "n_epochs = 100\n",
    "lr=0.01\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "877121ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.RNN(input_size=train_src_vocab_size, hidden_size=300, num_layers=100, batch_first=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3bb3b2e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15, 20, 42,  4,  8, 15, 22, 20, 41, 13, 10, 15,  4,  4, 15, 50, 22,  8,\n",
       "         20, 15, 10, 41, 35, -1, -1, -1, -1, -1, -1],\n",
       "        [25, 41, 40, 40, 50, 35, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [30, 15, 22, 15, 22, 39,  8,  6, 23, 13, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [33, 50, 36,  8, 40, 50, 50, 52,  8, 33, 50, 36, 22, 39,  8, 32, 50, 13,\n",
       "          8, 33, 50, 36, 13,  8, 23, 39, 41, 35, -1],\n",
       "        [15, 22,  4, 50, 10, 22, 15, 23, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [15,  8,  6, 23, 22, 42, 20,  8,  4, 41, 41, 35,  8,  3, 40, 41, 23,  4,\n",
       "         41,  8,  4, 15, 20,  8, 30, 50,  2, 22, 35],\n",
       "        [20, 25, 13, 41, 41, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [ 6, 23, 22,  8, 15,  8, 39, 41, 20,  8, 20, 25, 15,  4,  8, 15, 22,  8,\n",
       "          6, 25, 23, 22, 39, 41, 17, -1, -1, -1, -1]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7aef2b8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 53, got 29",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_seq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/rnn.py:467\u001b[0m, in \u001b[0;36mRNN.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    464\u001b[0m     hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m hx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 467\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRNN_TANH\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRNN_RELU\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/rnn.py:229\u001b[0m, in \u001b[0;36mRNNBase.check_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_forward_args\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, hidden: Tensor, batch_sizes: Optional[Tensor]):\n\u001b[0;32m--> 229\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m     expected_hidden_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes)\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden, expected_hidden_size)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/rnn.py:205\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput must have \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m dimensions, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    203\u001b[0m             expected_input_dim, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()))\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    206\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    207\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 53, got 29"
     ]
    }
   ],
   "source": [
    "rnn(input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b6c8adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 29])\n",
      "tensor([[297, 492,  59, 380, 264, 458, 100,  59, 116, 424,  -1,  -1,  -1,  -1,\n",
      "          -1,  -1],\n",
      "        [201,  44,  74,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
      "          -1,  -1],\n",
      "        [ 77, 134,  64,  59, 290,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
      "          -1,  -1],\n",
      "        [  4,  59, 439,  59, 393,  59, 211,  59,   4, 164,  59, 300, 134, 174,\n",
      "          -1,  -1],\n",
      "        [380, 395, 228, 544,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
      "          -1,  -1],\n",
      "        [544, 134,  59, 468, 316,  59, 289,  59,  55, 184,  92,  59, 466,  59,\n",
      "          77, 432],\n",
      "        [369, 184,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
      "          -1,  -1],\n",
      "        [468,  59, 544, 134,  59, 516,  59,  18,  73,  59, 380,  59, 322, 380,\n",
      "         174,  -1]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "For unbatched 2-D input, hx should also be 2-D but got 3-D tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      6\u001b[0m input_seq\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 7\u001b[0m output, hidden \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_seq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target_seq\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mlong())\n\u001b[1;32m      9\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_hidden(batch_size)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Passing in the input and hidden state into the model and obtaining outputs\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m out, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Reshaping the outputs such that it can be fit into the fully connected layer\u001b[39;00m\n\u001b[1;32m     26\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_dim)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/rnn.py:445\u001b[0m, in \u001b[0;36mRNN.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    444\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m hx\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 445\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    446\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor unbatched 2-D input, hx should also be 2-D but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhx\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-D tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    447\u001b[0m         hx \u001b[38;5;241m=\u001b[39m hx\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: For unbatched 2-D input, hx should also be 2-D but got 3-D tensor"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs+1):\n",
    "    for input_seq, target_seq in seq_dataloader:\n",
    "        print(input_seq.shape)\n",
    "        print(target_seq)\n",
    "        optimizer.zero_grad()\n",
    "        input_seq.to(device)\n",
    "        output, hidden = model(input_seq)\n",
    "        loss = criterion(output, target_seq.view(-1).long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print('end')\n",
    "        \n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e0d34add",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "For unbatched 2-D input, hx should also be 2-D but got 3-D tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [55]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad() \u001b[38;5;66;03m# Clears existing gradients from previous epoch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m input_seq\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 5\u001b[0m output, hidden \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_seq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target_seq\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mlong())\n\u001b[1;32m      7\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward() \u001b[38;5;66;03m# Does backpropagation and calculates gradients\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [50]\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_hidden(batch_size)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Passing in the input and hidden state into the model and obtaining outputs\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m out, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Reshaping the outputs such that it can be fit into the fully connected layer\u001b[39;00m\n\u001b[1;32m     26\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_dim)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/rnn.py:445\u001b[0m, in \u001b[0;36mRNN.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    444\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m hx\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 445\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    446\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor unbatched 2-D input, hx should also be 2-D but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhx\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-D tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    447\u001b[0m         hx \u001b[38;5;241m=\u001b[39m hx\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: For unbatched 2-D input, hx should also be 2-D but got 3-D tensor"
     ]
    }
   ],
   "source": [
    "# Training Run\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "    input_seq.to(device)\n",
    "    output, hidden = model(input_seq)\n",
    "    loss = criterion(output, target_seq.view(-1).long())\n",
    "    loss.backward() # Does backpropagation and calculates gradients\n",
    "    optimizer.step() # Updates the weights accordingly\n",
    "    \n",
    "    if epoch%10 == 0:\n",
    "        print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fc6abbb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(max(train_source, key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0a800070",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_source_list = list(set([i for line in train_source for i in line]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "69c3c9a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{21,\n",
       " 23,\n",
       " 29,\n",
       " 33,\n",
       " 35,\n",
       " 40,\n",
       " 52,\n",
       " 57,\n",
       " 68,\n",
       " 73,\n",
       " 78,\n",
       " 83,\n",
       " 92,\n",
       " 95,\n",
       " 103,\n",
       " 105,\n",
       " 109,\n",
       " 113,\n",
       " 128,\n",
       " 130,\n",
       " 140,\n",
       " 156,\n",
       " 157,\n",
       " 200,\n",
       " 202,\n",
       " 227,\n",
       " 228,\n",
       " 229,\n",
       " 263,\n",
       " 268,\n",
       " 271,\n",
       " 289,\n",
       " 304,\n",
       " 311,\n",
       " 320,\n",
       " 327,\n",
       " 342,\n",
       " 369,\n",
       " 382,\n",
       " 402,\n",
       " 416,\n",
       " 437,\n",
       " 453,\n",
       " 455,\n",
       " 456,\n",
       " 497,\n",
       " 498,\n",
       " 513,\n",
       " 557,\n",
       " 575,\n",
       " 584,\n",
       " 601,\n",
       " 619}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_source_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04a9886",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
